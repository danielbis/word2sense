{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()\n",
    "tf.executing_eagerly()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecordPrep: \n",
    "    \n",
    "    def __init__(self, _vocab_corpus_path, _sense_corpus_path, _tf_records_path):\n",
    "        self.vocab_corpus_path = _vocab_corpus_path\n",
    "        self.sense_corpus_path = _sense_corpus_path\n",
    "        self.tf_records_path = _tf_records_path\n",
    "    \n",
    "    def sequence_to_tf_example(self, sequence_1, sequence_2):\n",
    "            ex = tf.train.SequenceExample()\n",
    "            # A non-sequential feature of our example\n",
    "            sequence_length_1 = len(sequence_1) # list of word ids\n",
    "            sequence_length_2 = len(sequence_2) # list of sense ids\n",
    "            if sequence_length_1 != sequence_length_2:\n",
    "                raise Exception(\"Sequence lengths not equal: %d, %d\" % (sequence_length_1, sequence_length_2))\n",
    "            ex.context.feature[\"length_1\"].int64_list.value.append(sequence_length_1)\n",
    "            ex.context.feature[\"length_2\"].int64_list.value.append(sequence_length_2)\n",
    "\n",
    "\n",
    "            # Feature lists for the two sequential features of our example\n",
    "            fl_tokens_1 = ex.feature_lists.feature_list[\"vocab_ids\"]\n",
    "            fl_tokens_2 = ex.feature_lists.feature_list[\"sense_ids\"]\n",
    "\n",
    "            for token in sequence_1:\n",
    "                fl_tokens_1.feature.add().int64_list.value.append(token)        \n",
    "\n",
    "            for token in sequence_2:\n",
    "                fl_tokens_2.feature.add().int64_list.value.append(token)\n",
    "\n",
    "            return ex\n",
    "   \n",
    "    @staticmethod\n",
    "    def parse(ex):\n",
    "        '''\n",
    "        Explain to TF how to go froma  serialized example back to tensors\n",
    "        :param ex:\n",
    "        :return:\n",
    "        '''\n",
    "        context_features = {\n",
    "            \"length_1\": tf.FixedLenFeature([], dtype=tf.int64),\n",
    "            \"length_2\": tf.FixedLenFeature([], dtype=tf.int64)\n",
    "        }\n",
    "        sequence_features = {\n",
    "            \"vocab_ids\": tf.FixedLenSequenceFeature([], dtype=tf.int64),\n",
    "            \"sense_ids\": tf.FixedLenSequenceFeature([], dtype=tf.int64),\n",
    "\n",
    "        }\n",
    "\n",
    "        # Parse the example (returns a dictionary of tensors)\n",
    "        context_parsed, sequence_parsed = tf.parse_single_sequence_example(\n",
    "            serialized=ex,\n",
    "            context_features=context_features,\n",
    "            sequence_features=sequence_features\n",
    "        )\n",
    "        return {\"seq_1\": sequence_parsed[\"vocab_ids\"], \"length_1\": context_parsed[\"length_1\"],\n",
    "                \"seq_2\": sequence_parsed[\"sense_ids\"], \"length_2\": context_parsed[\"length_2\"]}\n",
    "    \n",
    "    def import_corpus_pickles(self):\n",
    "        \n",
    "        vocab_files = os.listdir(self.vocab_corpus_path)\n",
    "        sense_files = os.listdir(self.sense_corpus_path)\n",
    "        \n",
    "        \n",
    "        for _file in zip(vocab_files, sense_files):\n",
    "            if _file[0].split('/')[-1] != _file[1].split('/')[-1]:\n",
    "                raise Exception(\"Vocab and sense files do not match \\n%s\\n%s\" % \n",
    "                                (_file[0].split('/')[-1], _file[1].split('/')[-1]))\n",
    "            else:\n",
    "                vocab_document, sense_document = self.import_document_pickles(self.vocab_corpus_path +'/' + _file[0],\n",
    "                                                                              self.sense_corpus_path + '/' + _file[1])\n",
    "                self.serialize_doc(vocab_document, sense_document, _file[0])\n",
    "                \n",
    "            \n",
    "        return vocab_document, sense_document\n",
    "    \n",
    "    def import_document_pickles(self, vocab_corpus_path, sense_corpus_path):\n",
    "\n",
    "        vocab_document = pickle.load(open(vocab_corpus_path, 'rb'))\n",
    "        sense_document = pickle.load(open(sense_corpus_path, 'rb'))\n",
    "\n",
    "        return vocab_document, sense_document\n",
    "    \n",
    "    \n",
    "    def serialize_doc(self, vocab_list, sense_list, f_name):\n",
    "        print(len(vocab_list))\n",
    "        record_filename = self.tf_records_path + '/' + f_name + '.tfrecord'\n",
    "        print(\"Serializing file %s into tfrecord, number of examples: %d\" % (f_name, len(vocab_list)))\n",
    "        \n",
    "        with open(record_filename, 'w') as f:\n",
    "            writer = tf.python_io.TFRecordWriter(f.name)\n",
    "            for sentence in zip(vocab_list, sense_list):\n",
    "                #print(sentence[0], sentence[1])\n",
    "                example = self.sequence_to_tf_example(sentence[0], sentence[1])\n",
    "                writer.write(example.SerializeToString())\n",
    "    \n",
    "    def read_dataset(self):\n",
    "        # Read a tf record file. This makes a dataset of raw TFRecords\n",
    "        dataset = tf.data.TFRecordDataset(os.listdir(self.tf_records_path))\n",
    "        # Apply/map the parse function to every record. Now the dataset is a bunch of dictionaries of Tensors\n",
    "        dataset =  dataset.map(self.parse,num_parallel_calls=5)\n",
    "        #Shuffle the dataset\n",
    "        #dataset = dataset.shuffle(buffer_size=10000)\n",
    "        \n",
    "        return dataset\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sense_test_dir = '/Users/daniel/Desktop/Research/WSD_Data/ontonotes-release-5.0/api/test_sense'\n",
    "vocab_test_dir = '/Users/daniel/Desktop/Research/WSD_Data/ontonotes-release-5.0/api/test_vocab'\n",
    "tf_test_dir = '/Users/daniel/Desktop/Research/WSD_Data/ontonotes-release-5.0/api/test_tf'\n",
    "def test_class(test_dir1, test_dir2, test_dir3):\n",
    "    rprep = RecordPrep(test_dir1, test_dir2, test_dir3)\n",
    "    rprep.import_corpus_pickles()\n",
    "    _dset = rprep.read_dataset()\n",
    "    iterator = tf.data.Iterator.from_structure(_dset.output_types,\n",
    "                                               _dset.output_shapes)\n",
    "    training_init_op = iterator.make_initializer(_dset)\n",
    "\n",
    "    # This is an op that gets the next element from the iterator\n",
    "    next_element = iterator.get_next()\n",
    "\n",
    "    return next_element, training_init_op, iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_elem, init_op, iterator = test_class(vocab_test_dir, sense_test_dir, tf_test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'import_documents_pickles' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-433a33751d01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimport_documents_pickles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Users/daniel/Desktop/Research/WSD_Data/ontonotes-release-5.0/api/corpus/ids/pickles/bc#cctv#00#cctv_0000@all@cctv@bc@en@on.pickle'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'import_documents_pickles' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "import_documents_pickles('/Users/daniel/Desktop/Research/WSD_Data/ontonotes-release-5.0/api/corpus/ids/pickles/bc#cctv#00#cctv_0000@all@cctv@bc@en@on.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_iterator = tf.python_io.tf_record_iterator(path='/Users/daniel/Desktop/Research/WSD_Data/ontonotes-release-5.0/api/test_tf/bc#cctv#00#cctv_0000@all@cctv@bc@en@on.pickle.tfrecord')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for string_record in record_iterator:\n",
    "    example = tf.train.Example()\n",
    "    i += 1\n",
    "    example.ParseFromString(string_record)\n",
    "    \n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq1 = [1,2,3,4,5]\n",
    "seq2 = [6,7,8,9,10,11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialize_doc(vocab_list, sense_list):\n",
    "    examples = []\n",
    "    print(len(vocab_list))\n",
    "    for sentence in zip(vocab_list, sense_list):\n",
    "        #print(sentence[0], sentence[1])\n",
    "        ex = sequence_to_tf_example(sentence[0], sentence[1])\n",
    "        examples.append(ex)\n",
    "    print(len(examples))\n",
    "    return examples\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_list, sense_list = import_documents_pickles(\"/Users/daniel/Desktop/Research/WSD_Data/ontonotes-release-5.0/api/corpus/ids/pickles/bc#cctv#00#cctv_0000@all@cctv@bc@en@on.pickle\",\n",
    "                        \"/Users/daniel/Desktop/Research/WSD_Data/ontonotes-release-5.0/api/corpus/senses/pickles/bc#cctv#00#cctv_0000@all@cctv@bc@en@on.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = [[1, 2, 3], [4, 5, 1], [1, 2]]\n",
    "label_sequences = [[0, 1, 0], [1, 0, 0], [1, 1]]\n",
    " \n",
    "def make_example(sequence, labels):\n",
    "    # The object we return\n",
    "    ex = tf.train.SequenceExample()\n",
    "    # A non-sequential feature of our example\n",
    "    sequence_length = len(sequence)\n",
    "    ex.context.feature[\"length\"].int64_list.value.append(sequence_length)\n",
    "    # Feature lists for the two sequential features of our example\n",
    "    fl_tokens = ex.feature_lists.feature_list[\"tokens\"]\n",
    "    fl_labels = ex.feature_lists.feature_list[\"labels\"]\n",
    "    for token, label in zip(sequence, labels):\n",
    "        nested = fl_tokens.feature.add(ex.feature_lists.feature_list[\"nested\"])\n",
    "        for token in sequence:\n",
    "            nested.feature.add().int64_list.value.append(token)\n",
    "        fl_labels.feature.add().int64_list.value.append(label)\n",
    "    return ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exmpls = serialize_doc(vocab_list, sense_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = \"/Users/daniel/Desktop/Research/WSD_Data/ontonotes-release-5.0/api/corpus/senses/pickles/bc#cctv#00#cctv_0000@all@cctv@bc@en@on.pickle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1.split('/')[-1].replace('.pickle', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Can't convert non-rectangular Python sequence to Tensor.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-2a8b1593578c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msense_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mrelated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/ops/resource_variable_ops.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, variable_def, import_scope, constraint)\u001b[0m\n\u001b[1;32m    310\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m           \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m           constraint=constraint)\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m   \u001b[0;31m# pylint: disable=unused-argument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/ops/resource_variable_ops.pyc\u001b[0m in \u001b[0;36m_init_from_args\u001b[0;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, constraint)\u001b[0m\n\u001b[1;32m    441\u001b[0m           \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Initializer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m             initial_value = ops.convert_to_tensor(\n\u001b[0;32m--> 443\u001b[0;31m                 initial_value, name=\"initial_value\", dtype=dtype)\n\u001b[0m\u001b[1;32m    444\u001b[0m           \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m           if (self._in_graph_mode and initial_value is not None and\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, preferred_dtype)\u001b[0m\n\u001b[1;32m   1009\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1010\u001b[0m       \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1011\u001b[0;31m       as_ref=False)\n\u001b[0m\u001b[1;32m   1012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, ctx)\u001b[0m\n\u001b[1;32m   1105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1107\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/constant_op.pyc\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    215\u001b[0m                                          as_ref=False):\n\u001b[1;32m    216\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/constant_op.pyc\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name, verify_shape)\u001b[0m\n\u001b[1;32m    165\u001b[0m   \u001b[0mctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/constant_op.pyc\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Can't convert non-rectangular Python sequence to Tensor."
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "\n",
    "sense_ids = tf.contrib.eager.Variable([[1,2,3], [1,5,0], [1,5,7], [2,3,10], [2,0,0]])\n",
    "related = tf.contrib.eager.Variable([[0],[0,1],[0,2],[1,0], [1,2,8,4,5],[2,1,5], [3,0]], [1,5,7,9], [4,5] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(5, 3) dtype=int32, numpy=\n",
       "array([[ 1,  2,  3],\n",
       "       [ 1,  5,  0],\n",
       "       [ 1,  5,  7],\n",
       "       [ 2,  3, 58],\n",
       "       [ 2,  0,  0]], dtype=int32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1 2 3]\n",
      " [1 5 7]], shape=(2, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "e = tf.nn.embedding_lookup(b, [0,2])\n",
    "print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=65, shape=(3, 3), dtype=int32, numpy=\n",
       "array([[ 1,  5,  0],\n",
       "       [ 1,  5,  7],\n",
       "       [ 2,  3, 58]], dtype=int32)>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.embedding_lookup(b, e[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = ET.parse('/Users/daniel/Desktop/Research/WSD_Data/ontonotes-release-5.0/data/files/data/english/metadata/sense-inventories/absorb-v.xml')\n",
    "root = tree.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for child in root.findall('sense'):\n",
    "    onto_sense = child.get('n')\n",
    "    print('onto: ', int(onto_sense))\n",
    "    for s in child.findall('mappings/wn'):\n",
    "        if s.text is not None:\n",
    "            wn_sense = [int(a) for a in s.text.split(',')]\n",
    "            print(wn_sense)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path = '/Users/daniel/Desktop/Research/WSD_Data/ontonotes-release-5.0/data/files/data/english/metadata/sense-inventories'\n",
    "files = os.listdir('/Users/daniel/Desktop/Research/WSD_Data/ontonotes-release-5.0/data/files/data/english/metadata/sense-inventories')\n",
    "for f in files[:10]:\n",
    "    print(\"%s/%s\" %(path,f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tf.contrib.eager.Variable(tf.ones([2,4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'ResourceVariable' object does not support item assignment",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-66ca98831ab4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'ResourceVariable' object does not support item assignment"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "t[1] = tf.contrib.eager.Variable(tf.zeros([1,4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(3\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
